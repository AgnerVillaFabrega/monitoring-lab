# Gu√≠a Completa: Stack de Observabilidad E-commerce

## üìã Resumen del Stack

| Componente | Puerto | Funci√≥n Principal | Tecnolog√≠a |
|------------|--------|-------------------|------------|
| **Grafana** | 3000 | Visualizaci√≥n unificada de logs, m√©tricas y trazas | Grafana OSS |
| **Loki** | 3100 | Agregaci√≥n y consulta de logs centralizados | Grafana Loki |
| **Tempo** | 3200 | Almacenamiento y consulta de trazas distribuidas | Grafana Tempo |
| **Promtail** | - | Recolecci√≥n autom√°tica de logs de Docker | Grafana Promtail |
| **3 Microservicios Go** | 8081-8083 | Servicios de negocio con instrumentaci√≥n completa | Go + Gin + OpenTelemetry |
| **Traffic Generator** | - | Simulaci√≥n de tr√°fico realista y patrones de uso | Go + OpenTelemetry |

**Credenciales Grafana**: `admin/admin123`

## üîÑ Flujo Completo de Observabilidad

### Arquitectura Visual
```
[HTTP Request] ‚Üí [Microservicio Go] ‚Üí [OpenTelemetry Tracer] ‚Üí [Tempo]
                       ‚Üì                                          ‚Üë
                 [Logrus Logger] ‚Üí [Docker stdout] ‚Üí [Promtail] ‚Üí [Loki]
                                                                   ‚Üì
                                                              [Grafana]
                                                         (Correlaci√≥n por trace_id)
```

### Proceso Detallado Paso a Paso

1. **Generaci√≥n de Request**
   - Traffic Generator o usuario real env√≠a HTTP request
   - Request incluye headers HTTP est√°ndar

2. **Recepci√≥n en Microservicio**
   - Gin middleware de OpenTelemetry intercepta autom√°ticamente
   - Se crea un nuevo **span** con trace_id √∫nico
   - Se extrae trace context si viene de otro servicio (propagaci√≥n)

3. **Instrumentaci√≥n Autom√°tica**
   - Cada handler HTTP se instrumenta autom√°ticamente
   - Se registran: m√©todo, URL, status code, duraci√≥n
   - Errores se capturan como span events

4. **Logging Estructurado**
   - Logrus genera logs JSON con campos estructurados
   - **trace_id** se incluye autom√°ticamente en cada log
   - Logs salen por Docker stdout

5. **Recolecci√≥n de Logs**
   - Promtail lee logs de Docker daemon (`/var/run/docker.sock`)
   - Parsea JSON y extrae labels (service, level, etc.)
   - Env√≠a a Loki via HTTP API

6. **Env√≠o de Trazas**
   - OpenTelemetry SDK exporta spans a Tempo
   - Protocolo: OTLP gRPC (puerto 4317)
   - Batching autom√°tico para eficiencia

7. **Visualizaci√≥n en Grafana**
   - Datasources configurados: Loki (logs) + Tempo (trazas)
   - **Correlaci√≥n autom√°tica** por trace_id
   - Dashboard unificado con m√∫ltiples perspectivas

## üèóÔ∏è Componentes T√©cnicos Detallados

### Grafana - Centro de Observabilidad
- **Dashboard Principal**: "E-commerce Lab Overview"
- **Datasources autom√°ticos**: Loki y Tempo pre-configurados
- **Funcionalidades clave**:
  - Log exploration con LogQL
  - Trace search con TraceQL
  - Correlaci√≥n autom√°tica logs ‚Üî trazas
  - Service map generado autom√°ticamente
  - Alerting (configuraci√≥n manual)

### Loki - Agregaci√≥n de Logs
- **Arquitectura**: Index + Chunks storage
- **Indexing**: Por labels (service, level, host)
- **Formato**: JSON logs con campos estructurados
- **LogQL queries**: Similar a PromQL pero para logs
- **Retenci√≥n**: Configurable (default: ilimitada en desarrollo)

### Tempo - Trazas Distribuidas  
- **Protocolo**: OTLP (OpenTelemetry Protocol) sobre gRPC
- **Storage**: Local filesystem (desarrollo) / S3 (producci√≥n)
- **TraceQL**: Lenguaje de consulta para trazas complejas
- **Service Graph**: Generado autom√°ticamente desde spans

### Promtail - Log Collector
- **Input**: Docker container logs via socket
- **Processing**: Label extraction, JSON parsing
- **Output**: HTTP push a Loki
- **Configuration**: YAML declarativo

### Microservicios Go - Fuentes de Telemetr√≠a
Cada servicio implementa el mismo patr√≥n de instrumentaci√≥n:

```go
// Tracer initialization
tracer := otel.Tracer("service-name")

// HTTP middleware
router.Use(otelgin.Middleware("service-name"))

// HTTP client instrumentation  
httpClient := &http.Client{
    Transport: otelhttp.NewTransport(http.DefaultTransport)
}

// Structured logging with trace context
logrus.WithField("trace_id", span.SpanContext().TraceID().String())
```

## üåê Servicios y Comunicaci√≥n

### user-service (Puerto 8081)
**Funciones**:
- Autenticaci√≥n JWT (login/logout)
- Registro de usuarios
- Gesti√≥n de perfiles
- Endpoints de favoritos

**Comunicaci√≥n Saliente**:
- ‚Üí product-service (obtener favoritos del usuario)

### product-service (Puerto 8082)  
**Funciones**:
- Cat√°logo de productos
- B√∫squedas y filtros
- Gesti√≥n de inventario
- Productos trending

**Comunicaci√≥n**: Solo recibe requests (no hace llamadas salientes)

### order-service (Puerto 8083)
**Funciones**:
- Creaci√≥n de √≥rdenes
- Procesamiento de pagos
- Estados de orden
- Hist√≥rico de compras

**Comunicaci√≥n Saliente**:
- ‚Üí user-service (validar usuario existente)
- ‚Üí product-service (reservar inventario)

### traffic-generator
**Funciones**:
- Genera tr√°fico realista 24/7
- Simula m√∫ltiples usuarios simult√°neos
- Incluye failures y timeouts intencionales

**Patrones de Tr√°fico**:
- **User flows** (~5s): login, registro, consulta perfiles
- **Product flows** (~4s): browning, b√∫squedas, inventario  
- **Order flows** (~10s): creaci√≥n orden completa + pago
- **Advanced flows** (variable): analytics, recomendaciones, refunds

## üîç Trazabilidad Distribuida en Acci√≥n

### ¬øC√≥mo Funciona la Correlaci√≥n?

Cuando **order-service** crea una orden:

1. **Request inicial**: `POST /orders` ‚Üí genera `trace_id: abc123`
2. **Span ra√≠z**: "create_order" en order-service
3. **Child span 1**: HTTP call a user-service ‚Üí hereda trace_id
4. **Child span 2**: HTTP call a product-service ‚Üí hereda trace_id  
5. **Logs correlacionados**: Todos los logs de estos 3 servicios incluyen `trace_id: abc123`

### Ejemplo de Service Map Resultante
```
[traffic-generator] ‚Üí [order-service] ‚Üí [user-service]
                           ‚Üì
                      [product-service]
```

**M√©tricas autom√°ticas por conexi√≥n**:
- Request rate (req/s)
- Error rate (%)
- Latencia P50/P95/P99
- Success rate

## üéØ Casos de Uso Pr√°cticos

### 1. Debugging de Error de Producci√≥n

**Escenario**: "Los usuarios no pueden completar √≥rdenes desde las 14:30"

**Proceso de investigaci√≥n**:

1. **Grafana Dashboard** ‚Üí secci√≥n "Business Metrics"
2. **Identificar patr√≥n**: Orders success rate cay√≥ de 95% a 30%
3. **Log Explorer** ‚Üí filtrar por:
   ```
   {service="order-service"} |= "error" | json | level="ERROR"
   ```
4. **Encontrar trace_id** en log de error espec√≠fico
5. **Trace Explorer** ‚Üí buscar trace_id completo
6. **Analizar spans**: ¬øCu√°l fall√≥? ¬øuser-service? ¬øproduct-service?
7. **Log drill-down**: Ver logs espec√≠ficos de span problem√°tico

**Resultado t√≠pico**: En 2-3 minutos identificas la causa ra√≠z

### 2. Optimizaci√≥n de Performance

**Escenario**: "La app est√° lenta, usuarios se quejan"

**Proceso de an√°lisis**:

1. **Service Map**: Identificar servicios con alta latencia
2. **Trace search**: 
   ```
   {duration > 2s} && {service.name="order-service"}
   ```
3. **Span analysis**: ¬øQu√© operaci√≥n consume m√°s tiempo?
4. **Log correlation**: Ver logs de esa operaci√≥n espec√≠fica
5. **Pattern identification**: ¬øEs siempre la misma query? ¬øTimeout de red?

### 3. Monitoreo Proactivo

**Alertas sugeridas** (configuraci√≥n manual en Grafana):
- Error rate > 5% por 2 minutos
- Latencia P95 > 3 segundos por 5 minutos  
- Service unavailable por 30 segundos
- √ìrdenes fallidas > 20% por 5 minutos

## üìä M√©tricas Clave Disponibles

### M√©tricas T√©cnicas (Autom√°ticas)
- **Request Rate**: requests/segundo por servicio y endpoint
- **Error Rate**: % de HTTP 4xx/5xx por servicio
- **Latency Distribution**: P50, P95, P99 por operaci√≥n
- **Service Dependencies**: Map de llamadas inter-servicios
- **Span Duration**: Tiempo por operaci√≥n espec√≠fica

### M√©tricas de Negocio (En logs estructurados)
- **User Registration Rate**: nuevos usuarios por per√≠odo
- **Login Success Rate**: % de logins exitosos vs fallidos  
- **Product Search Volume**: b√∫squedas por t√©rmino/categor√≠a
- **Order Completion Rate**: % √≥rdenes finalizadas vs abandonadas
- **Payment Success Rate**: % pagos exitosos vs rechazados
- **Inventory Turnover**: productos m√°s reservados

### KPIs Dashboard Incluidos
- Total de √≥rdenes procesadas
- Revenue tracking (simulado)
- Productos m√°s populares
- Patrones de tr√°fico por hora
- Health status de todos los servicios

## üöÄ Comandos de Operaci√≥n Diaria

### Startup y Health Check
```bash
# Levantar stack completo
make up

# Verificar que todo est√© funcionando
make health

# Ver el dashboard principal
open http://localhost:3000
```

### Debugging y Troubleshooting
```bash
# Ver logs de servicio espec√≠fico
make logs-service SERVICE=order-service

# Ver logs con filtro de errores (usando herramientas locales)
make logs-service SERVICE=user-service | grep ERROR

# Ver estado detallado de contenedores
make status
```

### Testing y Validaci√≥n
```bash  
# Probar endpoints manualmente
make test-endpoints

# Verificar conectividad a stack de observabilidad
curl http://localhost:3100/ready  # Loki
curl http://localhost:3200/ready  # Tempo  
curl http://localhost:3000/api/health  # Grafana
```

## ‚ö° Quick Start para Aprendizaje

### Primer uso (5 minutos)
1. `make up` ‚Üí esperar 30 segundos
2. Abrir http://localhost:3000 (admin/admin123)  
3. Ir a "E-commerce Lab Overview" dashboard
4. Observar m√©tricas en tiempo real (traffic generator ya est√° corriendo)

### Simulaci√≥n de error (learning exercise)
```bash
# Generar error intencional
curl -X POST http://localhost:8081/auth/login \
  -H "Content-Type: application/json" \  
  -d '{"email":"invalid","password":"wrong"}'

# Buscar en Grafana logs: level="ERROR" email="invalid"
# Encontrar trace_id en el log
# Buscar ese trace_id en Tempo para ver span completo
```

### Trace de request completo (learning exercise)
```bash
# Generar orden completa (user ‚Üí product ‚Üí order)
curl -X POST http://localhost:8083/orders \
  -H "Content-Type: application/json" \
  -d '{"user_id":1,"products":[{"id":1,"quantity":2}]}'

# En Grafana Tempo, buscar:
{service.name="order-service"} && {span.name="create_order"}

# Ver√°s el service map completo: order‚Üíuser + order‚Üíproduct
```

## üèÜ Ventajas de Este Stack

### T√©cnicas
- **Una sola herramienta**: Grafana para logs, m√©tricas y trazas
- **Correlaci√≥n autom√°tica**: trace_id enlaza todo
- **Open source**: Sin vendor lock-in
- **Escalable**: Loki y Tempo dise√±ados para volumen
- **Est√°ndares**: OpenTelemetry es vendor-neutral

### De Negocio  
- **Mean Time To Detection**: De horas ‚Üí minutos
- **Mean Time To Resolution**: De horas ‚Üí minutos
- **Proactive monitoring**: Detectar antes que usuarios reporten
- **Cost effective**: Herramientas gratuitas vs soluciones comerciales
- **Learning curve**: Grafana es ampliamente conocido

### Educativas
- **Hands-on learning**: Stack completo funcionando en minutos
- **Real patterns**: Tr√°fico realista con failures y latencia
- **Industry standards**: OpenTelemetry, Grafana stack
- **Microservices patterns**: Service communication, distributed tracing
- **DevOps skills**: Docker, observability, monitoring

---

## üìö Recursos de Aprendizaje

### Documentaci√≥n Oficial
- [OpenTelemetry Docs](https://opentelemetry.io/docs/)
- [Grafana Observability](https://grafana.com/docs/)
- [LogQL Language](https://grafana.com/docs/loki/latest/logql/)
- [TraceQL Language](https://grafana.com/docs/tempo/latest/traceql/)

### Conceptos Clave a Dominar
1. **Distributed Tracing**: Spans, trace context, service maps
2. **Structured Logging**: JSON logs, log correlation  
3. **Observability vs Monitoring**: Diferencias y cu√°ndo usar cada uno
4. **SRE Practices**: SLIs, SLOs, error budgets

**Stack Status**: ‚úÖ Production-ready con patrones de la industria